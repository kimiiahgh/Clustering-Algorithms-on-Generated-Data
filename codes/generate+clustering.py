# -*- coding: utf-8 -*-
"""DM2.1*.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XnRtOakutvu87_lp1nC6aqLpRiBrVSqy
"""


from sklearn.datasets import make_blobs, make_moons, make_circles
from pandas import DataFrame

import numpy as np
import matplotlib.pyplot as plt
from sklearn.mixture import GaussianMixture
from scipy.stats import norm, multivariate_normal

def generate_data(n_data, means, covariances, weights):
    """creates a list of data points"""
    n_clusters, n_features = means.shape
    data = np.zeros((n_data, n_features))
    for i in range(n_data):
        # pick a cluster id and create data from this cluster
        k = np.random.choice(n_clusters, size = 1, p = weights)[0]
        x = np.random.multivariate_normal(means[k], covariances[k])
        data[i] = x
    return data

# Model parameters, including the mean
# covariance matrix and the weights for each cluster
init_means = np.array([
    [-3, -2],
    [8, -1],
    [8, -4],
    [6,4],
    [-5,4],
    [1,4]
])

init_covariances = np.array([
    [[2, 0.], [0., 2]],
    [[.09, 0], [0, .09]],
    [[.09, 0], [0, .09]],
    [[3,.2],[.2,.2]],
    [[3,.2],[.2,.2]],
    [[.3,0],[0,0]]
])

init_weights = [ 1/2 , 1/8 , 1/8 , 1/16, 1/16 , 1/8]

# generate data
np.random.seed(4)
X = generate_data(7000, init_means, init_covariances, init_weights)
plt.plot(X[:, 0], X[:, 1], 'ko')
plt.tight_layout()

import scipy.spatial.distance as distance
import sys

# Returns the distance between two vectors
def dist(vecA, vecB):
    return np.sqrt(np.power(vecA - vecB, 2).sum())

# This class describes the data structure and method of operation for CURE clustering.
class CureCluster:
    def __init__(self, id__, center__):
        self.points = center__
        self.repPoints = center__
        self.center = center__
        self.index = [id__]
        
    def __repr__(self):
        return "Cluster " + " Size: " + str(len(self.points))
    
    # Computes and stores the centroid of this cluster, based on its points
    def computeCentroid(self, clust):
        totalPoints_1 = len(self.index)
        totalPoints_2 = len(clust.index)
        self.center = (self.center*totalPoints_1 + clust.center*totalPoints_2) / (totalPoints_1 + totalPoints_2)
    
    # Computes and stores representative points for this cluster
    def generateRepPoints(self, numRepPoints, alpha):
        tempSet = None
        for i in range(1, numRepPoints+1):
            maxDist = 0
            maxPoint = None
            for p in range(0, len(self.index)):
                if i == 1:
                    minDist = dist(self.points[p,:], self.center)
                else:
                    X = np.vstack([tempSet, self.points[p, :]])
                    tmpDist = distance.pdist(X)
                    minDist = tmpDist.min()
                if minDist >= maxDist:
                    maxDist = minDist
                    maxPoint = self.points[p,:]
            if tempSet is None:
                tempSet = maxPoint
            else:
                tempSet = np.vstack((tempSet, maxPoint))
        for j in range(len(tempSet)):
            if self.repPoints is None:
                self.repPoints = tempSet[j,:] + alpha * (self.center - tempSet[j,:])
            else:
                self.repPoints = np.vstack((self.repPoints, tempSet[j,:] + alpha * (self.center - tempSet[j,:])))

    # Computes and stores distance between this cluster and the other one.
    def distRep(self, clust):
        distRep = float('inf')
        for repA in self.repPoints:
            if type(clust.repPoints[0]) != list:
                repB = clust.repPoints
                distTemp = dist(repA, repB)
                if distTemp < distRep:
                    distRep = distTemp
            else:
                for repB in clust.repPoints:
                    distTemp = dist(repA, repB)
                    if distTemp < distRep:
                        distRep = distTemp
        return distRep

    # Merges this cluster with the given cluster, recomputing the centroid and the representative points.
    def mergeWithCluster(self, clust, numRepPoints, alpha):
        self.computeCentroid(clust)
        self.points = np.vstack((self.points, clust.points))
        self.index = np.append(self.index, clust.index)
        self.repPoints = None
        self.generateRepPoints(numRepPoints, alpha)

# Describe the process of the CURE algorithm
def runCURE(data, numRepPoints, alpha, numDesCluster):

    # Initialization
    Clusters = []
    numCluster = len(data)
    numPts = len(data)
    distCluster = np.ones([len(data), len(data)])
    distCluster = distCluster * float('inf')
    for idPoint in range(len(data)):
        newClust = CureCluster(idPoint, data[idPoint,:])
        Clusters.append(newClust)
    for row in range(0, numPts):
    	for col in range(0, row):
    		distCluster[row][col] = dist(Clusters[row].center, Clusters[col].center)
    while numCluster > numDesCluster:
        if np.mod(numCluster, 50) == 0:
            print('Cluster count:', numCluster)

        # Find a pair of closet clusters
        minIndex = np.where(distCluster == np.min(distCluster))
        minIndex1 = minIndex[0][0]
        minIndex2 = minIndex[1][0]

        # Merge
        Clusters[minIndex1].mergeWithCluster(Clusters[minIndex2], numRepPoints, alpha)
        # Update the distCluster matrix
        for i in range(0, minIndex1):
            distCluster[minIndex1, i] = Clusters[minIndex1].distRep(Clusters[i])
        for i in range(minIndex1+1, numCluster):
            distCluster[i, minIndex1] = Clusters[minIndex1].distRep(Clusters[i])
        # Delete the merged cluster and its disCluster vector.
        distCluster = np.delete(distCluster, minIndex2, axis=0)
        distCluster = np.delete(distCluster, minIndex2, axis=1)
        del Clusters[minIndex2]
        numCluster = numCluster - 1

    print('Cluster count:', numCluster)
    # Generate sample labels
    Label = [0] * numPts
    for i in range(0, len(Clusters)):
        for j in range(0, len(Clusters[i].index)):
            Label[Clusters[i].index[j]] = i + 1

    return Label

from sklearn import metrics

# The number of representative points
numRepPoints = 5
# Shrink factor
alpha = 0.1
# Desired cluster number
numDesCluster = 6
Label_pre = runCURE(X, numRepPoints, alpha, numDesCluster)
print(Label_pre)

c1=[]
c2=[]
c3=[]
c4=[]
c5=[]
c6=[]
X1=np.array(X)
for i in range(0,7000):
  if Label_pre[i]==1:
    c1.append(X1[i])
  elif Label_pre[i]==2:
    c2.append(X1[i]) 
  elif Label_pre[i]==3:
    c3.append(X1[i]) 
  elif Label_pre[i]==4:
    c4.append(X1[i])
  elif Label_pre[i]==5:
    c5.append(X1[i]) 
  elif Label_pre[i]==6:
    c6.append(X1[i])  

c1=np.array(c1)
c2=np.array(c2)
c3=np.array(c3)
c4=np.array(c4)
c5=np.array(c5)
c6=np.array(c6)   
plt.figure(figsize=(10,10))  
plt.scatter(c1[:,0], c1[:, 1], s = 100,marker='o' ,c = 'blue', label = 'Cluster1')
plt.scatter(c2[:,0], c2[:, 1], s = 100,marker='<' ,c = 'red', label = 'Cluster2')
plt.scatter(c3[:,0], c3[:, 1], s = 100,marker='>' ,c = 'green', label = 'Cluster3')
plt.scatter(c4[:,0], c4[:, 1], s = 100,marker='s' ,c = 'cyan', label = 'Cluster4')
plt.scatter(c5[:,0], c5[:, 1], s = 100,marker='*' ,c = 'magenta', label = 'Cluster5')
plt.scatter(c6[:,0], c6[:, 1], s = 100,marker='P' ,c = 'yellow', label = 'Cluster6')     
plt.title('Clustering using cure algorithm alpha=0.1')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

numRepPoints = 5
alpha = 0.3
numDesCluster = 6
Label_pre1 = runCURE(X, numRepPoints, alpha, numDesCluster)
cu1=[]
cu2=[]
cu3=[]
cu4=[]
cu5=[]
cu6=[]
X1=np.array(X)
for i in range(0,7000):
  if Label_pre1[i]==1:
    cu1.append(X1[i])
  elif Label_pre1[i]==2:
    cu2.append(X1[i]) 
  elif Label_pre1[i]==3:
    cu3.append(X1[i]) 
  elif Label_pre1[i]==4:
    cu4.append(X1[i])
  elif Label_pre1[i]==5:
    cu5.append(X1[i]) 
  elif Label_pre1[i]==6:
    cu6.append(X1[i])  

cu1=np.array(cu1)
cu2=np.array(cu2)
cu3=np.array(cu3)
cu4=np.array(cu4)
cu5=np.array(cu5)
cu6=np.array(cu6)   
plt.figure(figsize=(10,10))  
plt.scatter(cu1[:,0], cu1[:, 1], s = 100,marker='o' ,c = 'blue', label = 'Cluster1')
plt.scatter(cu2[:,0], cu2[:, 1], s = 100,marker='<' ,c = 'red', label = 'Cluster2')
plt.scatter(cu3[:,0], cu3[:, 1], s = 100,marker='>' ,c = 'green', label = 'Cluster3')
plt.scatter(cu4[:,0], cu4[:, 1], s = 100,marker='s' ,c = 'cyan', label = 'Cluster4')
plt.scatter(cu5[:,0], cu5[:, 1], s = 100,marker='*' ,c = 'magenta', label = 'Cluster5')
plt.scatter(cu6[:,0], cu6[:, 1], s = 100,marker='P' ,c = 'yellow', label = 'Cluster6')     
plt.title('Clustering using cure algorithm alpha=0.3')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

numRepPoints = 5
alpha = 0.6
numDesCluster = 6
Label_pre2 = runCURE(X, numRepPoints, alpha, numDesCluster)
cur1=[]
cur2=[]
cur3=[]
cur4=[]
cur5=[]
cur6=[]
X1=np.array(X)
for i in range(0,7000):
  if Label_pre2[i]==1:
    cur1.append(X1[i])
  elif Label_pre2[i]==2:
    cur2.append(X1[i]) 
  elif Label_pre2[i]==3:
    cur3.append(X1[i]) 
  elif Label_pre2[i]==4:
    cur4.append(X1[i])
  elif Label_pre2[i]==5:
    cur5.append(X1[i]) 
  elif Label_pre2[i]==6:
    cur6.append(X1[i])  

cur1=np.array(cur1)
cur2=np.array(cur2)
cur3=np.array(cur3)
cur4=np.array(cur4)
cur5=np.array(cur5)
cur6=np.array(cur6)   
plt.figure(figsize=(10,10))  
plt.scatter(cur1[:,0], cur1[:, 1], s = 100,marker='o' ,c = 'blue', label = 'Cluster1')
plt.scatter(cur2[:,0], cur2[:, 1], s = 100,marker='<' ,c = 'red', label = 'Cluster2')
plt.scatter(cur3[:,0], cur3[:, 1], s = 100,marker='>' ,c = 'green', label = 'Cluster3')
plt.scatter(cur4[:,0], cur4[:, 1], s = 100,marker='s' ,c = 'cyan', label = 'Cluster4')
plt.scatter(cur5[:,0], cur5[:, 1], s = 100,marker='*' ,c = 'magenta', label = 'Cluster5')
plt.scatter(cur6[:,0], cur6[:, 1], s = 100,marker='P' ,c = 'yellow', label = 'Cluster6')     
plt.title('Clustering using cure algorithm alpha=0.6')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

X1=np.array(X)
from fcmeans import FCM
fcm = FCM(n_clusters=6)
fcm.fit(X)
fcm_labels = fcm.predict(X)
if 6 in fcm_labels:
  print("exist")
fcm_centers = fcm.centers
print(fcm_centers)

cf1=[]
cf2=[]
cf3=[]
cf4=[]
cf5=[]
cf6=[]
X1=np.array(X)
for i in range(0,7000):
  if fcm_labels[i]==1:
    cf1.append(X1[i])
  elif fcm_labels[i]==2:
    cf2.append(X1[i]) 
  elif fcm_labels[i]==3:
    cf3.append(X1[i]) 
  elif fcm_labels[i]==4:
    cf4.append(X1[i])
  elif fcm_labels[i]==5:
    cf5.append(X1[i]) 
  elif fcm_labels[i]==0:
    cf6.append(X1[i])  

cf1=np.array(cf1)
cf2=np.array(cf2)
cf3=np.array(cf3)
cf4=np.array(cf4)
cf5=np.array(cf5)
cf6.append(fcm_centers[0])
cf6=np.array(cf6)   
plt.figure(figsize=(10,10))  
plt.scatter(cf1[:,0], cf1[:, 1], s = 100,marker='o' ,c = 'blue', label = 'Cluster1')
plt.scatter(cf2[:,0], cf2[:, 1], s = 100,marker='<' ,c = 'red', label = 'Cluster2')
plt.scatter(cf3[:,0], cf3[:, 1], s = 100,marker='>' ,c = 'green', label = 'Cluster3')
plt.scatter(cf4[:,0], cf4[:, 1], s = 100,marker='s' ,c = 'cyan', label = 'Cluster4')
plt.scatter(cf5[:,0], cf5[:, 1], s = 100,marker='*' ,c = 'magenta', label = 'Cluster5')
plt.scatter(cf6[:,0], cf6[:, 1], s = 100,marker='P' ,c = 'yellow', label = 'Cluster6')     
plt.title('Clustering using fuzzy c means algorithm k=6')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

X1=np.array(X)
from fcmeans import FCM
fcm1 = FCM(n_clusters=8)
fcm1.fit(X)
fcm_labels1 = fcm1.predict(X)

fcm_centers1 = fcm1.centers
print(fcm_centers1) 
cfu1=[]
cfu2=[]
cfu3=[]
cfu4=[]
cfu5=[]
cfu6=[]
cfu7=[]
cfu8=[]
X1=np.array(X)
for i in range(0,7000):
  if fcm_labels1[i]==1:
    cfu1.append(X1[i])
  elif fcm_labels1[i]==2:
    cfu2.append(X1[i]) 
  elif fcm_labels1[i]==3:
    cfu3.append(X1[i]) 
  elif fcm_labels1[i]==4:
    cfu4.append(X1[i])
  elif fcm_labels1[i]==5:
    cfu5.append(X1[i]) 
  elif fcm_labels1[i]==6:
    cfu6.append(X1[i])  
  elif fcm_labels1[i]==7:
    cfu7.append(X1[i])  
  elif fcm_labels1[i]==0:
    cfu8.append(X1[i]) 
cfu1=np.array(cfu1)
cfu2=np.array(cfu2)
cfu3=np.array(cfu3)
cfu4=np.array(cfu4)
cfu5=np.array(cfu5)
cfu8.append(fcm_centers1[0])
cfu6=np.array(cfu6)  
cfu7=np.array(cfu7)
cfu8=np.array(cfu8) 
plt.figure(figsize=(10,10))  
plt.scatter(cfu1[:,0], cfu1[:, 1], s = 100,marker='o' ,c = 'blue', label = 'Cluster1')
plt.scatter(cfu2[:,0], cfu2[:, 1], s = 100,marker='<' ,c = 'red', label = 'Cluster2')
plt.scatter(cfu3[:,0], cfu3[:, 1], s = 100,marker='>' ,c = 'green', label = 'Cluster3')
plt.scatter(cfu4[:,0], cfu4[:, 1], s = 100,marker='s' ,c = 'cyan', label = 'Cluster4')
plt.scatter(cfu5[:,0], cfu5[:, 1], s = 100,marker='*' ,c = 'magenta', label = 'Cluster5')
plt.scatter(cfu6[:,0], cfu6[:, 1], s = 100,marker='P' ,c = 'yellow', label = 'Cluster6')  
plt.scatter(cfu7[:,0], cfu7[:, 1], s = 100,marker="h" ,c = 'hotpink', label = 'Cluster7')
plt.scatter(cfu8[:,0], cfu8[:, 1], s = 100,marker="X" ,c = 'black', label = 'Cluster8')     
plt.title('Clustering using fuzzy c means algorithm k=8')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

X1=np.array(X)
from fcmeans import FCM
fcm2 = FCM(n_clusters=10)
fcm2.fit(X)
fcm_labels2= fcm2.predict(X)

fcm_centers2 = fcm2.centers
print(fcm_centers2) 
cfuz1=[]
cfuz2=[]
cfuz3=[]
cfuz4=[]
cfuz5=[]
cfuz6=[]
cfuz7=[]
cfuz8=[]
cfuz9=[]
cfuz10=[]
X1=np.array(X)
for i in range(0,7000):
  if fcm_labels2[i]==1:
    cfuz1.append(X1[i])
  elif fcm_labels2[i]==2:
    cfuz2.append(X1[i]) 
  elif fcm_labels2[i]==3:
    cfuz3.append(X1[i]) 
  elif fcm_labels2[i]==4:
    cfuz4.append(X1[i])
  elif fcm_labels2[i]==5:
    cfuz5.append(X1[i]) 
  elif fcm_labels2[i]==6:
    cfuz6.append(X1[i])  
  elif fcm_labels2[i]==7:
    cfuz7.append(X1[i])  
  elif fcm_labels2[i]==8:
    cfuz8.append(X1[i])  
  elif fcm_labels2[i]==9:
    cfuz9.append(X1[i])    
  elif fcm_labels2[i]==0:
    cfuz10.append(X1[i])
cfuz1=np.array(cfu1)
cfuz2=np.array(cfu2)
cfuz3=np.array(cfu3)
cfuz4=np.array(cfu4)
cfuz5=np.array(cfu5)
cfuz10.append(fcm_centers1[0])
cfuz6=np.array(cfuz6)  
cfuz7=np.array(cfuz7)
cfuz8=np.array(cfuz8)
cfuz9=np.array(cfuz9)
cfuz10=np.array(cfuz10) 
plt.figure(figsize=(10,10))  
plt.scatter(cfuz1[:,0], cfuz1[:, 1], s = 100,marker='o' ,c = 'blue', label = 'Cluster1')
plt.scatter(cfuz2[:,0], cfuz2[:, 1], s = 100,marker='<' ,c = 'red', label = 'Cluster2')
plt.scatter(cfuz3[:,0], cfuz3[:, 1], s = 100,marker='>' ,c = 'green', label = 'Cluster3')
plt.scatter(cfuz4[:,0], cfuz4[:, 1], s = 100,marker='s' ,c = 'cyan', label = 'Cluster4')
plt.scatter(cfuz5[:,0], cfuz5[:, 1], s = 100,marker='*' ,c = 'magenta', label = 'Cluster5')
plt.scatter(cfuz6[:,0], cfuz6[:, 1], s = 100,marker='P' ,c = 'yellow', label = 'Cluster6') 
plt.scatter(cfuz7[:,0], cfuz7[:, 1], s = 100,marker="h" ,c = 'hotpink', label = 'Cluster7')
plt.scatter(cfuz8[:,0], cfuz8[:, 1], s = 100,marker="X" ,c = 'black', label = 'Cluster8') 
plt.scatter(cfuz9[:,0], cfuz9[:, 1], s = 100,marker="D" ,c = 'darkviolet', label = 'Cluster9')
plt.scatter(cfuz10[:,0], cfuz10[:, 1], s = 100,marker="^" ,c = 'lawngreen', label = 'Cluster10')      
plt.title('Clustering using fuzzy c means algorithm k=10')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters = 6, init = 'k-means++')
y_pred = kmeans.fit_predict(X)

ck1=[]
ck2=[]
ck3=[]
ck4=[]
ck5=[]
ck6=[]
X1=np.array(X)
for i in range(0,7000):
  if y_pred[i]==1:
    ck1.append(X1[i])
  elif y_pred[i]==2:
    ck2.append(X1[i]) 
  elif y_pred[i]==3:
    ck3.append(X1[i]) 
  elif y_pred[i]==4:
    ck4.append(X1[i])
  elif y_pred[i]==5:
    ck5.append(X1[i]) 
  elif y_pred[i]==0:
    ck6.append(X1[i])  
ck6.append(kmeans.cluster_centers_[0])
ck1=np.array(ck1)
ck2=np.array(ck2)
ck3=np.array(ck3)
ck4=np.array(ck4)
ck5=np.array(ck5)
ck6=np.array(ck6)   
plt.figure(figsize=(10,10))  
plt.scatter(ck1[:,0], ck1[:, 1], s = 100,marker='o' ,c = 'blue', label = 'Cluster1')
plt.scatter(ck2[:,0], ck2[:, 1], s = 100,marker='<' ,c = 'red', label = 'Cluster2')
plt.scatter(ck3[:,0], ck3[:, 1], s = 100,marker='>' ,c = 'green', label = 'Cluster3')
plt.scatter(ck4[:,0], ck4[:, 1], s = 100,marker='s' ,c = 'cyan', label = 'Cluster4')
plt.scatter(ck5[:,0], ck5[:, 1], s = 100,marker='*' ,c = 'magenta', label = 'Cluster5')
plt.scatter(ck6[:,0], ck6[:, 1], s = 100,marker='P' ,c = 'yellow', label = 'Cluster6')     
plt.title('Clustering using kmeans algorithm k=6')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

kmeans1 = KMeans(n_clusters = 8, init = 'k-means++')
y_pred1 = kmeans1.fit_predict(X)
ckm1=[]
ckm2=[]
ckm3=[]
ckm4=[]
ckm5=[]
ckm6=[]
ckm7=[]
ckm8=[]
X1=np.array(X)
for i in range(0,7000):
  if y_pred1[i]==1:
    ckm1.append(X1[i])
  elif y_pred1[i]==2:
    ckm2.append(X1[i]) 
  elif y_pred1[i]==3:
    ckm3.append(X1[i]) 
  elif y_pred1[i]==4:
    ckm4.append(X1[i])
  elif y_pred1[i]==5:
    ckm5.append(X1[i]) 
  elif y_pred1[i]==6:
    ckm6.append(X1[i]) 
  elif y_pred1[i]==7:
    ckm7.append(X1[i])     
  elif y_pred1[i]==0:
    ckm8.append(X1[i])
ckm8.append(kmeans1.cluster_centers_[0])
ckm1=np.array(ckm1)
ckm2=np.array(ckm2)
ckm3=np.array(ckm3)
ckm4=np.array(ckm4)
ckm5=np.array(ckm5)
ckm6=np.array(ckm6) 
ckm7=np.array(ckm7)
ckm8=np.array(ckm8)   
plt.figure(figsize=(10,10))  
plt.scatter(ckm1[:,0], ckm1[:, 1], s = 100,marker='o' ,c = 'blue', label = 'Cluster1')
plt.scatter(ckm2[:,0], ckm2[:, 1], s = 100,marker='<' ,c = 'red', label = 'Cluster2')
plt.scatter(ckm3[:,0], ckm3[:, 1], s = 100,marker='>' ,c = 'green', label = 'Cluster3')
plt.scatter(ckm4[:,0], ckm4[:, 1], s = 100,marker='s' ,c = 'cyan', label = 'Cluster4')
plt.scatter(ckm5[:,0], ckm5[:, 1], s = 100,marker='*' ,c = 'magenta', label = 'Cluster5')
plt.scatter(ckm6[:,0], ckm6[:, 1], s = 100,marker='P' ,c = 'yellow', label = 'Cluster6')   
plt.scatter(ckm7[:,0], ckm7[:, 1], s = 100,marker="h" ,c = 'hotpink', label = 'Cluster7')
plt.scatter(ckm8[:,0], ckm8[:, 1], s = 100,marker="X" ,c = 'black', label = 'Cluster8')   
plt.title('Clustering using kmeans algorithm k=8')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

kmeans2 = KMeans(n_clusters = 10, init = 'k-means++')
y_pred2 = kmeans2.fit_predict(X)
ckme1=[]
ckme2=[]
ckme3=[]
ckme4=[]
ckme5=[]
ckme6=[]
ckme7=[]
ckme8=[]
ckme9=[]
ckme10=[]
X1=np.array(X)
for i in range(0,7000):
  if y_pred2[i]==1:
    ckme1.append(X1[i])
  elif y_pred2[i]==2:
    ckme2.append(X1[i]) 
  elif y_pred2[i]==3:
    ckme3.append(X1[i]) 
  elif y_pred2[i]==4:
    ckme4.append(X1[i])
  elif y_pred2[i]==5:
    ckme5.append(X1[i]) 
  elif y_pred2[i]==6:
    ckme6.append(X1[i]) 
  elif y_pred2[i]==7:
    ckme7.append(X1[i])     
  elif y_pred2[i]==8:
    ckme8.append(X1[i])
  elif y_pred2[i]==9:
    ckme9.append(X1[i])
  elif y_pred2[i]==0:
    ckme10.append(X1[i])
ckme10.append(kmeans2.cluster_centers_[0])    
ckme1=np.array(ckme1)
ckme2=np.array(ckme2)
ckme3=np.array(ckme3)
ckme4=np.array(ckme4)
ckme5=np.array(ckme5)
ckme6=np.array(ckme6) 
ckme7=np.array(ckme7)
ckme8=np.array(ckme8) 
ckme9=np.array(ckme9)
ckme10=np.array(ckme10)   
plt.figure(figsize=(10,10))  
plt.scatter(ckme1[:,0], ckme1[:, 1], s = 100,marker='o' ,c = 'blue', label = 'Cluster1')
plt.scatter(ckme2[:,0], ckme2[:, 1], s = 100,marker='<' ,c = 'red', label = 'Cluster2')
plt.scatter(ckme3[:,0], ckme3[:, 1], s = 100,marker='>' ,c = 'green', label = 'Cluster3')
plt.scatter(ckme4[:,0], ckme4[:, 1], s = 100,marker='s' ,c = 'cyan', label = 'Cluster4')
plt.scatter(ckme5[:,0], ckme5[:, 1], s = 100,marker='*' ,c = 'magenta', label = 'Cluster5')
plt.scatter(ckme6[:,0], ckme6[:, 1], s = 100,marker='P' ,c = 'yellow', label = 'Cluster6')   
plt.scatter(ckme7[:,0], ckme7[:, 1], s = 100,marker="h" ,c = 'hotpink', label = 'Cluster7')
plt.scatter(ckme8[:,0], ckme8[:, 1], s = 100,marker="X" ,c = 'black', label = 'Cluster8')
plt.scatter(ckme9[:,0], ckme9[:, 1], s = 100,marker="D" ,c = 'darkviolet', label = 'Cluster9')
plt.scatter(ckme10[:,0], ckme10[:, 1], s = 100,marker="^" ,c = 'lawngreen', label = 'Cluster10')
plt.title('Clustering using kmeans algorithm k=10')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

from sklearn.cluster import DBSCAN
DB1 = DBSCAN(eps=0.3, min_samples=3).fit(X)
y1=DB1.labels_
print(y1)
cd1=[]
cd2=[]
cd3=[]
cd4=[]
cd5=[]
cd6=[]
cd7=[]
cd8=[]
cd9=[]
cd10=[]
X1=np.array(X)
for i in range(0,7000):
  if y1[i]==0:
    cd1.append(X1[i])
  elif y1[i]==1:
    cd2.append(X1[i]) 
  elif y1[i]==2:
    cd3.append(X1[i]) 
  elif y1[i]==3:
    cd4.append(X1[i])
  elif y1[i]==4:
    cd5.append(X1[i]) 
  elif y1[i]==5:
    cd6.append(X1[i]) 
  elif y1[i]==6:
    cd7.append(X1[i])     
  elif y1[i]==7:
    cd8.append(X1[i])
  elif y1[i]==8:
    cd9.append(X1[i])
  elif y1[i]==9:
    cd10.append(X1[i])    
cd1=np.array(cd1)
cd2=np.array(cd2)
cd3=np.array(cd3)
cd4=np.array(cd4)
cd5=np.array(cd5)
cd6=np.array(cd7) 
cd8=np.array(cd8)
cd9=np.array(cd9) 
cd10=np.array(cd10)
cd7=np.array(cd7)   
plt.figure(figsize=(10,10))  
plt.scatter(cd1[:,0], cd1[:, 1], s = 100,marker='o' ,c = 'blue', label = 'Cluster1')
plt.scatter(cd2[:,0], cd2[:, 1], s = 100,marker='<' ,c = 'red', label = 'Cluster2')
plt.scatter(cd3[:,0], cd3[:, 1], s = 100,marker='>' ,c = 'green', label = 'Cluster3')
plt.scatter(cd4[:,0], cd4[:, 1], s = 100,marker='s' ,c = 'cyan', label = 'Cluster4')
plt.scatter(cd5[:,0], cd5[:, 1], s = 100,marker='*' ,c = 'magenta', label = 'Cluster5')
plt.scatter(cd6[:,0], cd6[:, 1], s = 100,marker='P' ,c = 'yellow', label = 'Cluster6')   
plt.scatter(cd7[:,0], cd7[:, 1], s = 100,marker="h" ,c = 'hotpink', label = 'Cluster7')
plt.scatter(cd8[:,0],  cd8[:, 1], s = 100,marker="X" ,c = 'black', label = 'Cluster8')
plt.scatter(cd9[:,0], cd9[:, 1], s = 100,marker="D" ,c = 'darkviolet', label = 'Cluster9')
plt.scatter(cd10[:,0], cd10[:, 1], s = 100,marker="^" ,c = 'lawngreen', label = 'Cluster10')
plt.title('Clustering using DBscan algorithm eps=0.3,minpts=3')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

DB1 = DBSCAN(eps=0.5, min_samples=3).fit(X)
y1=DB1.labels_
cd1=[]
cd2=[]
cd3=[]
cd4=[]
cd5=[]
cd6=[]
cd7=[]
cd8=[]
X1=np.array(X)
for i in range(0,7000):
  if y1[i]==0:
    cd1.append(X1[i])
  elif y1[i]==1:
    cd2.append(X1[i]) 
  elif y1[i]==2:
    cd3.append(X1[i]) 
  elif y1[i]==3:
    cd4.append(X1[i])
  elif y1[i]==4:
    cd5.append(X1[i]) 
  elif y1[i]==5:
    cd6.append(X1[i]) 
  elif y1[i]==6:
    cd7.append(X1[i])     
  elif y1[i]==7:
    cd8.append(X1[i])
    
cd1=np.array(cd1)
cd2=np.array(cd2)
cd3=np.array(cd3)
cd4=np.array(cd4)
cd5=np.array(cd5)
cd6=np.array(cd7) 
cd8=np.array(cd8)
cd7=np.array(cd7)   
plt.figure(figsize=(10,10))  
plt.scatter(cd1[:,0], cd1[:, 1], s = 100,marker='o' ,c = 'blue', label = 'Cluster1')
plt.scatter(cd2[:,0], cd2[:, 1], s = 100,marker='<' ,c = 'red', label = 'Cluster2')
plt.scatter(cd3[:,0], cd3[:, 1], s = 100,marker='>' ,c = 'green', label = 'Cluster3')
plt.scatter(cd4[:,0], cd4[:, 1], s = 100,marker='s' ,c = 'cyan', label = 'Cluster4')
plt.scatter(cd5[:,0], cd5[:, 1], s = 100,marker='*' ,c = 'magenta', label = 'Cluster5')
plt.scatter(cd6[:,0], cd6[:, 1], s = 100,marker='P' ,c = 'yellow', label = 'Cluster6')   
plt.scatter(cd7[:,0], cd7[:, 1], s = 100,marker="h" ,c = 'hotpink', label = 'Cluster7')
plt.scatter(cd8[:,0],  cd8[:, 1], s = 100,marker="X" ,c = 'black', label = 'Cluster8')
plt.title('Clustering using DBscan algorithm eps=0.5,minpts=3')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

DB1 = DBSCAN(eps=0.7, min_samples=3).fit(X)
y1=DB1.labels_
cd1=[]
cd2=[]
cd3=[]
cd4=[]
cd5=[]
cd6=[]
X1=np.array(X)
for i in range(0,7000):
  if y1[i]==0:
    cd1.append(X1[i])
  elif y1[i]==1:
    cd2.append(X1[i]) 
  elif y1[i]==2:
    cd3.append(X1[i]) 
  elif y1[i]==3:
    cd4.append(X1[i])
  elif y1[i]==4:
    cd5.append(X1[i]) 
  elif y1[i]==5:
    cd6.append(X1[i]) 

    
cd1=np.array(cd1)
cd2=np.array(cd2)
cd3=np.array(cd3)
cd4=np.array(cd4)
cd5=np.array(cd5)
cd6=np.array(cd7) 
  
plt.figure(figsize=(10,10))  
plt.scatter(cd1[:,0], cd1[:, 1], s = 100,marker='o' ,c = 'blue', label = 'Cluster1')
plt.scatter(cd2[:,0], cd2[:, 1], s = 100,marker='<' ,c = 'red', label = 'Cluster2')
plt.scatter(cd3[:,0], cd3[:, 1], s = 100,marker='>' ,c = 'green', label = 'Cluster3')
plt.scatter(cd4[:,0], cd4[:, 1], s = 100,marker='s' ,c = 'cyan', label = 'Cluster4')
plt.scatter(cd5[:,0], cd5[:, 1], s = 100,marker='*' ,c = 'magenta', label = 'Cluster5')
plt.scatter(cd6[:,0], cd6[:, 1], s = 100,marker='P' ,c = 'yellow', label = 'Cluster6')   

plt.title('Clustering using DBscan algorithm eps=0.7,minpts=3')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

for x in X1[0:2001]:
  print("[",x[0],",",x[1],"]",",")

!pip install metis

!gunzip metis-5.1.0.tar.gz

import networkx as nx
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

def plot2d_graph(graph):
    pos = nx.get_node_attributes(graph, 'pos')
    c = [colors[i % (len(colors))]
         for i in nx.get_node_attributes(graph, 'cluster').values()]
    if c:  # is set
        nx.draw(graph, pos, node_color=c, node_size=0.25)
    else:
        nx.draw(graph, pos, node_size=0.25)
    plt.show(block=False)


def plot2d_data(df):
    if (len(df.columns) > 3):
        print("Plot Warning: more than 2-Dimensions!")
    limit = len(df.index)
    matrix = []
    xx = []
    yy = []
    cc = []
    for i in range(limit):
        valor =str(df[0][i]).split(",")
        xx.append(float(valor[0]))
        yy.append(float(valor[1]))
        cc.append(float(df['cluster'][i]))
    dff = pd.DataFrame(matrix, columns=['x', 'y', 'cluster'])
    dff.plot.scatter(x='x',
                      y='y',
                      c='cluster', colormap='gist_rainbow')
    print('----------')
    colors = np.random.rand(limit)
    plt.scatter(xx, yy, s=cc, c=colors,alpha=0.5)
    plt.show()
import networkx as nx
from tqdm import tqdm
import metis
def euclidean_distance(a, b):
    newA= a[0].split(",")
    newA_int = [float(i) for i in newA]
    newB= b[0].split(",")
    newB_int = [float(i) for i in newB]
    return np.linalg.norm(np.array(newA_int) - np.array(newB_int))


def knn_graph(df, k, verbose=False):
    points = [p[1:] for p in df.itertuples()]
    g = nx.Graph()
    for i in range(0, len(points)):
        g.add_node(i)
    if verbose:
        print("Building kNN graph (k = %d)..." % (k))
    iterpoints = tqdm(enumerate(points), total=len(
        points)) if verbose else enumerate(points)
    for i, p in iterpoints:
        distances = list(map(lambda x: euclidean_distance(p, x), points))
        closests = np.argsort(distances)[1:k+1]  # second trough kth closest
        # print(distances[0])
        for c in closests:
            g.add_edge(i, c, weight=1.0 / distances[c], similarity=int(
                1.0 / distances[c] * 1e4))
        g.nodes[i]['pos'] = p
    g.graph['edge_weight_attr'] = 'similarity'
    return g


def part_graph(graph, k, df=None):
    edgecuts, parts = metis.part_graph(
        graph, 2, objtype='cut', ufactor=250)
    # print(edgecuts)
    for i, p in enumerate(graph.nodes()):
        graph.nodes[p]['cluster'] = parts[i]
    if df is not None:
        df['cluster'] = nx.get_node_attributes(graph, 'cluster').values()
    return graph


def pre_part_graph(graph, k, df=None, verbose=False):
    if verbose:
        print("Begin clustering...")
    clusters = 0
    for i, p in enumerate(graph.nodes()):
        graph.nodes[p]['cluster'] = 0
    cnts = {}
    cnts[0] = len(graph.nodes())

    while clusters < k - 1:
        maxc = -1
        maxcnt = 0
        for key, val in cnts.items():
            if val > maxcnt:
                maxcnt = val
                maxc = key
        s_nodes = [n for n in graph.nodes if graph.nodes[n]['cluster'] == maxc]
        s_graph = graph.subgraph(s_nodes)
        edgecuts, parts = metis.part_graph(
            s_graph, 2, objtype='cut', ufactor=250)
        new_part_cnt = 0
        for i, p in enumerate(s_graph.nodes()):
            if parts[i] == 1:
                graph.nodes[p]['cluster'] = clusters + 1
                new_part_cnt = new_part_cnt + 1
        cnts[maxc] = cnts[maxc] - new_part_cnt
        cnts[clusters + 1] = new_part_cnt
        clusters = clusters + 1

    edgecuts, parts = metis.part_graph(graph, k)
    if df is not None:
        df['cluster'] = nx.get_node_attributes(graph, 'cluster').values()
    return graph


def get_cluster(graph, clusters):
    nodes = [n for n in graph.nodes if graph.nodes[n]['cluster'] in clusters]
    return nodes


def connecting_edges(partitions, graph):
    cut_set = []
    for a in partitions[0]:
        for b in partitions[1]:
            if a in graph:
                if b in graph[a]:
                    cut_set.append((a, b))
    return cut_set


def min_cut_bisector(graph):
    graph = graph.copy()
    graph = part_graph(graph, 2)
    partitions = get_cluster(graph, [0]), get_cluster(graph, [1])
    return connecting_edges(partitions, graph)


def get_weights(graph, edges):
    return [graph[edge[0]][edge[1]]['weight'] for edge in edges]


def bisection_weights(graph, cluster):
    cluster = graph.subgraph(cluster)
    edges = min_cut_bisector(cluster)
    weights = get_weights(cluster, edges)
    return weights   
import itertools

def internal_interconnectivity(graph, cluster):
    return np.sum(bisection_weights(graph, cluster))


def relative_interconnectivity(graph, cluster_i, cluster_j):
    edges = connecting_edges((cluster_i, cluster_j), graph)
    EC = np.sum(get_weights(graph, edges))
    ECci, ECcj = internal_interconnectivity(
        graph, cluster_i), internal_interconnectivity(graph, cluster_j)
    return EC / ((ECci + ECcj) / 2.0)


def internal_closeness(graph, cluster):
    cluster = graph.subgraph(cluster)
    edges = cluster.edges()
    weights = get_weights(cluster, edges)
    return np.sum(weights)


def relative_closeness(graph, cluster_i, cluster_j):
    edges = connecting_edges((cluster_i, cluster_j), graph)
    if not edges:
        return 0.0
    else:
        SEC = np.mean(get_weights(graph, edges))
    Ci, Cj = internal_closeness(
        graph, cluster_i), internal_closeness(graph, cluster_j)
    SECci, SECcj = np.mean(bisection_weights(graph, cluster_i)), np.mean(
        bisection_weights(graph, cluster_j))
    return SEC / ((Ci / (Ci + Cj) * SECci) + (Cj / (Ci + Cj) * SECcj))


def merge_score(g, ci, cj, a):
    return relative_interconnectivity(
        g, ci, cj) * np.power(relative_closeness(g, ci, cj), a)


def merge_best(graph, df, a, k, verbose=False):
    clusters = np.unique(df['cluster'])
    max_score = 0
    ci, cj = -1, -1
    if len(clusters) <= k:
        return False

    for combination in itertools.combinations(clusters, 2):
        i, j = combination
        if i != j:
            if verbose:
                print("Checking c%d c%d" % (i, j))
            gi = get_cluster(graph, [i])
            gj = get_cluster(graph, [j])
            edges = connecting_edges(
                (gi, gj), graph)
            if not edges:
                continue
            ms = merge_score(graph, gi, gj, a)
            if verbose:
                print("Merge score: %f" % (ms))
            if ms > max_score:
                if verbose:
                    print("Better than: %f" % (max_score))
                max_score = ms
                ci, cj = i, j

    if max_score > 0:
        if verbose:
            print("Merging c%d and c%d" % (ci, cj))
        df.loc[df['cluster'] == cj, 'cluster'] = ci
        for i, p in enumerate(graph.nodes()):
            if graph.nodes[p]['cluster'] == cj:
                graph.nodes[p]['cluster'] = ci
    return max_score > 0


def cluster(df, k, knn=10, m=30, alpha=2.0, verbose=False, plot=False):
    graph = knn_graph(df, knn, verbose=True)
    graph = pre_part_graph(graph, m, df, verbose=True)
    iterm = tqdm(enumerate(range(m - k)), total=m-k)
    for i in iterm:
        merge_best(graph, df, alpha, k, verbose)
        if plot:
            plot2d_data(df)
    res = rebuild_labels(df)
    return res

def rebuild_labels(df):
    ans = df.copy()
    clusters = list(pd.DataFrame(df['cluster'].value_counts()).index)
    c = 1
    for i in clusters:
        ans.loc[df['cluster'] == i, 'cluster'] = c
        c = c + 1
    return ans

from clustviz import chameleon
res, h = chameleon.chameleon(X, k=1, alpha=2,plot=False)
